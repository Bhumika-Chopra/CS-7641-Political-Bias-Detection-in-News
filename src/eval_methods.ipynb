{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816a060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/nparikh44/scratch/miniconda/envs/simcse-h100/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## import libraries for generating visualizations and confusion matrix after loading hf models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cc3bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "def load_model_and_tokenizer(model_name):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "def predict(model, tokenizer, texts):\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    return predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb275b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded: 6209 samples\n",
      "Final dataset: 6202 samples\n",
      "Bias distribution: {0: 1273, 1: 549, 2: 644, 3: 776, 4: 2960}\n",
      "Train: 4961, Test: 1241\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "ds = load_dataset(\"lelouch0204/cleaned_allsides_v2.csv\")\n",
    "df = ds['train'].to_pandas()\n",
    "print(f\"Loaded: {len(df)} samples\")\n",
    "\n",
    "# Map bias labels (CORRECTED)\n",
    "bias_mapping = {\n",
    "    'left': 4,\n",
    "    'lean left': 3,\n",
    "    'center': 2,\n",
    "    'lean right': 1,\n",
    "    'right': 0\n",
    "}\n",
    "df['bias_label'] = df['Bias'].str.lower().str.strip().map(bias_mapping)\n",
    "df = df.dropna(subset=['bias_label', 'Text'])\n",
    "df['bias_label'] = df['bias_label'].astype(int)\n",
    "\n",
    "# Use existing clean_text or Text\n",
    "df['text_input'] = df['clean_text'].fillna(df['Text'])\n",
    "df = df[df['text_input'].str.len() > 50]\n",
    "\n",
    "print(f\"Final dataset: {len(df)} samples\")\n",
    "print(\"Bias distribution:\", df['bias_label'].value_counts().sort_index().to_dict())\n",
    "\n",
    "# Train-test split\n",
    "X_text = df['text_input'].values\n",
    "y = df['bias_label'].values\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train: {len(X_train_text)}, Test: {len(X_test_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5081c369",
   "metadata": {},
   "source": [
    "## SimCSE fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf90658",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.expanduser(\"~/scratch/experiments/allsides_finetuned_simcse_roberta_base/_10_5_epochs_updated_train_test_len_256/\")\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(MODEL_PATH)\n",
    "preds = predict(model, tokenizer, X_test_text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f0a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simcse-h100",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
